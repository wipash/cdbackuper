apiVersion: v1
kind: Namespace
metadata:
  name: cd-import
---
apiVersion: v1
kind: PersistentVolume
metadata:
  name: cd-archive-pv
spec:
  capacity:
    storage: 1Ti
  accessModes: [ ReadWriteMany ]
  persistentVolumeReclaimPolicy: Retain
  storageClassName: ""
  nfs:
    server: 172.20.0.1
    path: /volume1/Backup/Maurice/cd-archive
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: cd-archive-pvc
  namespace: cd-import
spec:
  accessModes: [ ReadWriteMany ]
  storageClassName: ""
  resources:
    requests:
      storage: 1Ti
  volumeName: cd-archive-pv
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: cd-watcher
  namespace: cd-import
data:
  cd-importer.sh: |
    #!/usr/bin/env bash
    set -Eeuo pipefail
    
    
    VERSION="1.0.2"
    # --- Configuration via env (with defaults) -------------------------------
    DATA_ROOT="${DATA_ROOT:-/data}"         # PVC mount
    DEVICE_GLOB="${DEVICE_GLOB:-/dev/sr*}"  # CD/DVD devices to watch
    RETRIES="${RETRIES:-3}"                 # ddrescue retry passes
    TIMEOUT="${TIMEOUT:-7200}"              # seconds, per-disc guard
    EXTRACT_FILES="${EXTRACT_FILES:-true}"  # true|false
    POLL_SECS="${POLL_SECS:-5}"
    NODE_NAME="${NODE_NAME:-$(cat /etc/hostname)}"
    # -------------------------------------------------------------------------
    
    mkdir -p /var/run/cd-import /mnt/work
    
    # FIX: Ensure /dev/fd exists for process substitution (missing in newer Talos/containerd)
    if [[ ! -e /dev/fd ]]; then
      ln -sf /proc/self/fd /dev/fd
    fi
    
    # Enhanced logging with device context
    log() {
      local dev_id="${1:-}"
      shift || true
      if [[ -n "$dev_id" ]]; then
        echo "[$(date -u +%FT%TZ)] [$NODE_NAME:$dev_id] $*"
      else
        echo "[$(date -u +%FT%TZ)] [$NODE_NAME] $*"
      fi
    }
    
    # FIX #4: Verify NFS mount at startup
    if ! mountpoint -q "$DATA_ROOT"; then
      log "" "FATAL: $DATA_ROOT is not mounted! Cannot proceed."
      exit 1
    fi
    log "" "✓ Confirmed $DATA_ROOT is mounted"
    
    has_media() {
      local dev="$1"
      # ID_CDROM_MEDIA=1 is a good signal; fallback to blkid TYPE
      if udevadm info --query=property --name="$dev" 2>/dev/null | grep -q '^ID_CDROM_MEDIA=1$'; then
        return 0
      fi
      if blkid -o value -s TYPE "$dev" &>/dev/null; then
        return 0
      fi
      return 1
    }
    
    disc_label() {
      local dev="$1"
      blkid -o value -s LABEL "$dev" 2>/dev/null || echo "unknown"
    }
    
    disc_uuid() {
      local dev="$1"
      blkid -o value -s UUID "$dev" 2>/dev/null || echo ""
    }
    
    dump_metadata() {
      local dev="$1" dest="$2"
      blkid -o export "$dev" > "$dest/blkid.txt" 2>/dev/null || true
    }
    
    iso_info_dump() {
      local iso="$1" dest="$2"
      isoinfo -d -i "$iso" > "$dest/isoinfo.txt" 2>/dev/null || true
    }
    
    convert_psd_previews() {
      local files_dir="$1"
      local dev_name="$2"
      local psd_count=0
      local converted_count=0
    
      # Count PSDs first
      psd_count=$(find "$files_dir" -type f -iname "*.psd" 2>/dev/null | wc -l)
    
      if [[ $psd_count -eq 0 ]]; then
        return 0
      fi
    
      log "$dev_name" "🖼️  Found $psd_count PSD file(s), generating jpgs..."
    
      # Convert each PSD
      find "$files_dir" -type f -iname "*.psd" -print0 2>/dev/null | while IFS= read -r -d '' psd; do
        local jpg="${psd%.psd}.jpg"
        if convert "${psd}[0]" -quality 85 "$jpg" 2>/dev/null; then
          # Match JPG timestamp to PSD
          touch -r "$psd" "$jpg" 2>/dev/null || true
          converted_count=$((converted_count + 1))
        else
          log "$dev_name" "⚠️  Failed to convert: $(basename "$psd")"
        fi
      done
    
      log "$dev_name" "✓ PSD conversion complete"
    }
    
    make_status() {
      local dest="$1" status="$2" msg="$3" iso="$4" started="$5" finished="$6" uuid="$7" is_retry="$8"
      local rescued="" rescued_pct="" read_errors=""
    
      # Parse job log (contains ddrescue output and all other logs)
      if [[ -f "$dest/job.log" ]]; then
        # Get the last "rescued:" line (final status)
        rescued=$(grep 'rescued:' "$dest/job.log" | tail -1 | awk '{print $2, $3}' || echo "unknown")
        # Get percentage
        rescued_pct=$(grep 'pct rescued:' "$dest/job.log" | tail -1 | awk '{print $3}' || echo "0%")
        # Read errors is field 6, need to strip trailing comma
        read_errors=$(grep 'read errors:' "$dest/job.log" | tail -1 | awk '{print $6}' | tr -d ',' || echo "0")
      fi
    
      # Track retry attempts and nodes
      local retry_nodes=""
      if [[ -f "$dest/status.json" ]]; then
        # Preserve previous nodes list
        retry_nodes=$(jq -r '.retry_nodes // [] | join(",")' "$dest/status.json" 2>/dev/null || echo "")
      fi
    
      if [[ "$is_retry" == "true" ]]; then
        # Append current node to retry list
        if [[ -n "$retry_nodes" ]]; then
          retry_nodes="${retry_nodes},${NODE_NAME}"
        else
          retry_nodes="${NODE_NAME}"
        fi
      fi
    
      jq -n --arg node "$NODE_NAME" \
            --arg status "$status" \
            --arg message "$msg" \
            --arg iso "$(basename "$iso")" \
            --arg started "$started" \
            --arg finished "$finished" \
            --arg uuid "$uuid" \
            --arg rescued "$rescued" \
            --arg rescued_pct "$rescued_pct" \
            --arg read_errors "$read_errors" \
            --arg is_retry "$is_retry" \
            --arg retry_nodes "$retry_nodes" \
            '{node:$node,status:$status,message:$message,iso:$iso,uuid:$uuid,started:$started,finished:$finished,is_retry:($is_retry=="true"),retry_nodes:(if $retry_nodes == "" then [] else ($retry_nodes|split(",")) end),ddrescue:{rescued:$rescued,rescued_pct:$rescued_pct,read_errors:$read_errors}}' \
        > "$dest/status.json"
    }
    
    send_discord_notification() {
      local status="$1"
      local label="$2"
      local rescued_pct="$3"
      local read_errors="$4"
      local outdir="$5"
      local dev_name="$6"
      local is_retry="${7:-false}"
    
      # Skip if webhook not configured
      [[ -z "${DISCORD_WEBHOOK_URL:-}" ]] && return 0
    
      local color emoji title description retry_info=""
    
      # Add retry information if this is a duplicate disc
      if [[ "$is_retry" == "true" ]]; then
        local retry_nodes=""
        if [[ -f "$outdir/status.json" ]]; then
          retry_nodes=$(jq -r '.retry_nodes // [] | join(", ")' "$outdir/status.json" 2>/dev/null || echo "")
        fi
        if [[ -n "$retry_nodes" ]]; then
          retry_info="\n🔄 **Retry attempt** (Previous: $retry_nodes)"
        else
          retry_info="\n🔄 **Retry attempt**"
        fi
      fi
    
      if [[ "$status" == "success" ]]; then
        color="3066993"  # Green
        emoji="✅"
        title="CD Archived Successfully"
        description="**Node:** $NODE_NAME  //  $dev_name\n**Label:** $label\n**Rescued:** $rescued_pct${retry_info}\n**Path:** $(basename "$outdir")\n\n💬 *Reply to add disc label*"
      else
        color="15158332"  # Red
        emoji="❌"
        title="CD Archive Failed/Partial"
    
        # Get last 5 lines of log for failure context
        local log_tail=""
        if [[ -f "$outdir/job.log" ]]; then
          log_tail=$(tail -5 "$outdir/job.log" | sed 's/"/\\"/g' || true)
        fi
    
        description="**Node:** $NODE_NAME  //  $dev_name\n**Label:** $label\n**Rescued:** $rescued_pct\n**Read Errors:** $read_errors${retry_info}\n**Path:** $(basename "$outdir")\n\n**Last log lines:**\n\`\`\`\n${log_tail}\n\`\`\`"
      fi
    
      # Send Discord webhook (with embed for nice formatting)
      curl -X POST "${DISCORD_WEBHOOK_URL}" \
        -H "Content-Type: application/json" \
        -d "{
          \"username\": \"CD Archiver\",
          \"embeds\": [{
            \"title\": \"$emoji $title\",
            \"description\": \"$description\",
            \"color\": $color,
            \"footer\": {
              \"text\": \"$(basename "$outdir")\"
            },
            \"timestamp\": \"$(date -u +%Y-%m-%dT%H:%M:%SZ)\"
          }]
        }" 2>/dev/null || true
    }
    
    process_disc() {
      local dev="$1"
      local dev_name
      dev_name=$(basename "$dev")
      local started finished label uuid outdir iso rc=0 timeout_pid is_retry=false job_log
    
      # FIX #3: Clean mount point before use
      umount /mnt/work 2>/dev/null || true
    
      # FIX #3: Setup trap for cleanup
      cleanup_mount() {
        umount /mnt/work 2>/dev/null || true
      }
      trap cleanup_mount EXIT INT TERM
    
      label="$(disc_label "$dev" | tr -cd '[:alnum:]_. -' | tr ' ' '_')"
      uuid="$(disc_uuid "$dev" | tr -cd '[:alnum:]-')"
      started="$(date -u +%Y-%m-%dT%H%M%SZ)"
    
      # Skip generic/meaningless labels when naming directories
      case "$label" in
        NEW|My_Disc|unknown)
          label_suffix=""
          ;;
        *)
          label_suffix="_${label}"
          ;;
      esac
    
      if [[ -n "$uuid" ]]; then
        outdir="$DATA_ROOT/${uuid}${label_suffix}"
      else
        outdir="$DATA_ROOT/${started}${label_suffix}"
      fi
    
      # Detect duplicate disc by checking if output directory already exists
      if [[ -d "$outdir" && (-f "$outdir/status.json" || -f "$outdir/ddrescue.mapfile") ]]; then
        is_retry=true
        # Backup previous job log if it exists (before we start redirecting to it)
        if [[ -f "$outdir/job.log" ]]; then
          cp "$outdir/job.log" "$outdir/job.log.backup-$(date -u +%Y%m%d-%H%M%S)"
        fi
      else
        mkdir -p "$outdir"
      fi
    
      # Redirect all subsequent output to job.log (and still show in stdout for kubectl logs)
      job_log="$outdir/job.log"
      exec > >(tee -a "$job_log") 2>&1
    
      # Log initialization info (now captured in job.log)
      if [[ "$is_retry" == "true" ]]; then
        log "$dev_name" "════════════════════════════════════════"
        log "$dev_name" "🔄 DUPLICATE DETECTED - Retrying recovery"
        log "$dev_name" "   Label: '$label'"
        log "$dev_name" "   Output: $(basename "$outdir")"
    
        # Read previous attempt info
        if [[ -f "$outdir/status.json" ]]; then
          local prev_nodes prev_pct
          prev_nodes=$(jq -r '.node // "unknown"' "$outdir/status.json" 2>/dev/null || echo "unknown")
          prev_pct=$(jq -r '.ddrescue.rescued_pct // "unknown"' "$outdir/status.json" 2>/dev/null || echo "unknown")
          log "$dev_name" "   Previous: Node=$prev_nodes, Rescued=$prev_pct"
        fi
    
        log "$dev_name" "   Current: Node=$NODE_NAME"
        log "$dev_name" "   Will resume using existing mapfile"
        log "$dev_name" "════════════════════════════════════════"
      else
        log "$dev_name" "════════════════════════════════════════"
        log "$dev_name" "🔵 STARTED - Label: '$label'"
        log "$dev_name" "   Output: $(basename "$outdir")"
        log "$dev_name" "════════════════════════════════════════"
      fi
    
      dump_metadata "$dev" "$outdir"
    
      iso="$outdir/disc.iso"
      touch "$outdir/.in-progress"
    
      # FIX #2: Track timeout guard PID so we can kill it later
      (
        sleep "$TIMEOUT"
        if [[ -f "$outdir/.in-progress" ]]; then
          log "$dev_name" "⏱️  TIMEOUT hit, stopping ddrescue"
          pkill -f "ddrescue .* $dev" || true
        fi
      ) &
      timeout_pid=$!
    
      # ddrescue fast pass + a few retries
      log "$dev_name" "📀 Running ddrescue (fast pass + $RETRIES retries)..."
      set +e
      ddrescue -d -b 2048 -n "$dev" "$iso" "$outdir/ddrescue.mapfile" 2>&1 | sed 's/\x1b\[[0-9;]*[a-zA-Z]//g' | cat -s
      ddrescue -d -b 2048 -r"$RETRIES" "$dev" "$iso" "$outdir/ddrescue.mapfile" 2>&1 | sed 's/\x1b\[[0-9;]*[a-zA-Z]//g' | cat -s
      rc=$?
      set -e
    
      # FIX #2: Kill timeout guard if still running
      if kill -0 "$timeout_pid" 2>/dev/null; then
        kill "$timeout_pid" 2>/dev/null || true
        wait "$timeout_pid" 2>/dev/null || true
      fi
    
      log "$dev_name" "📝 ddrescue completed with exit code: $rc"
    
      iso_info_dump "$iso" "$outdir"
    
      # FIX #5: Try to extract files (support both ISO 9660 and UDF formats)
      local files_extracted=false
      local mount_error=""
      if [[ "${EXTRACT_FILES}" == "true" && -s "$iso" ]]; then
        log "$dev_name" "📂 Extracting files from ISO..."
        mkdir -p "$outdir/files"
    
        # Try mounting (works for both ISO 9660 and UDF formats)
        mount_error=$(mount -o loop,ro "$iso" /mnt/work 2>&1) || true
        if mountpoint -q /mnt/work; then
          rsync -a /mnt/work/ "$outdir/files/" || true
          umount /mnt/work || true
          files_extracted=true
          log "$dev_name" "✓ Files extracted successfully"
    
          # Generate PSD previews
          convert_psd_previews "$outdir/files" "$dev_name"
        else
          log "$dev_name" "⚠️  Could not mount ISO - may be corrupt or unsupported format"
          if [[ -n "$mount_error" ]]; then
            log "$dev_name" "   Mount error: ${mount_error:0:200}"
            echo "$mount_error" > "$outdir/mount-error.txt"
          fi
        fi
      fi
    
      finished="$(date -u +%Y-%m-%dT%H%M%SZ)"
    
      # Auto-delete ISO on successful extraction
      if [[ "$rc" -eq 0 && "$files_extracted" == "true" && "${DELETE_ISO_ON_SUCCESS:-true}" == "true" ]]; then
        log "$dev_name" "🗑️  Deleting ISO to save space"
        rm -f "$iso"
      fi
    
      # Parse rescue stats for notification
      local rescued_pct="unknown"
      local rescued_pct_num=0
      local read_errors="0"
      if [[ -f "$outdir/job.log" ]]; then
        rescued_pct=$(grep 'pct rescued:' "$outdir/job.log" | tail -1 | awk '{print $3}' || echo "unknown")
        # Extract numeric value for comparison (e.g., "99.5%" -> 99.5)
        rescued_pct_num="${rescued_pct%\%}"
        # Read errors is field 6, need to strip trailing comma
        read_errors=$(grep 'read errors:' "$outdir/job.log" | tail -1 | awk '{print $6}' | tr -d ',' || echo "0")
      fi
    
      # Success criteria:
      # - If EXTRACT_FILES=true: require files to be extracted successfully (with >95% rescued as fallback)
      # - If EXTRACT_FILES=false: require ddrescue exit code 0
      local is_success=false
      if [[ "${EXTRACT_FILES}" == "true" ]]; then
        # Success if files extracted AND (ddrescue succeeded OR rescued >= 95%)
        if [[ "$files_extracted" == "true" ]]; then
          if [[ $rc -eq 0 ]] || [[ $(echo "$rescued_pct_num >= 95" | bc -l 2>/dev/null || echo 0) -eq 1 ]]; then
            is_success=true
          fi
        fi
      else
        # Just wanted the ISO, so success if ddrescue succeeded
        if [[ $rc -eq 0 ]]; then
          is_success=true
        fi
      fi
    
      if [[ "$is_success" == "true" ]]; then
        make_status "$outdir" "success" "Recovered successfully" "$iso" "$started" "$finished" "$uuid" "$is_retry"
        send_discord_notification "success" "$label" "$rescued_pct" "$read_errors" "$outdir" "$dev_name" "$is_retry"
        log "$dev_name" "════════════════════════════════════════"
        log "$dev_name" "✅ SUCCESS - Rescued: $rescued_pct"
        if [[ "$is_retry" == "true" ]]; then
          log "$dev_name" "   🔄 This was a retry attempt"
        fi
        log "$dev_name" "════════════════════════════════════════"
      else
        make_status "$outdir" "partial_or_failed" "ddrescue exited rc=$rc after retries" "$iso" "$started" "$finished" "$uuid" "$is_retry"
        send_discord_notification "failure" "$label" "$rescued_pct" "$read_errors" "$outdir" "$dev_name" "$is_retry"
        log "$dev_name" "════════════════════════════════════════"
        log "$dev_name" "❌ FAILED - Rescued: $rescued_pct, Errors: $read_errors"
        if [[ "$is_retry" == "true" ]]; then
          log "$dev_name" "   🔄 This was a retry attempt - try another node/drive?"
        fi
        log "$dev_name" "   See: $(basename "$outdir")/status.json"
        log "$dev_name" "════════════════════════════════════════"
      fi
    
      rm -f "$outdir/.in-progress"
      sync || true
    
      # Eject disc
      log "$dev_name" "⏏️  Ejecting disc..."
      if eject "$dev" 2>/dev/null; then
        # Wait for device to actually report no media (max 30s)
        local wait_count=0
        while has_media "$dev" && [[ $wait_count -lt 30 ]]; do
          sleep 1
          wait_count=$((wait_count + 1))
        done
        if [[ $wait_count -ge 30 ]]; then
          log "$dev_name" "⚠️  Device still reporting media after 30s"
        fi
        # Extra safety buffer
        sleep 2
      else
        log "$dev_name" "⚠️  Eject command failed"
      fi
    
      # Cleanup trap on normal exit
      trap - EXIT INT TERM
      cleanup_mount
    }
    
    # FIX #6: Track background jobs to avoid zombie accumulation
    declare -A active_jobs
    
    # Main loop
    log "" "🚀 Starting CD watcher v$VERSION - monitoring: $DEVICE_GLOB"
    log "" "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
    
    while true; do
      # Clean up finished jobs
      for pid in "${!active_jobs[@]}"; do
        if ! kill -0 "$pid" 2>/dev/null; then
          wait "$pid" 2>/dev/null || true
          finished_dev="${active_jobs[$pid]}"
          unset 'active_jobs[$pid]'
          log "$(basename "$finished_dev")" "Job completed (PID: $pid)"
        fi
      done
    
      for dev in $DEVICE_GLOB; do
        [[ -e "$dev" ]] || continue
        lock="/var/run/cd-import/$(basename "$dev").lock"
    
        if has_media "$dev"; then
          # FIX #1: Atomic lock using mkdir instead of touch + check
          if mkdir "$lock" 2>/dev/null; then
            (
              process_disc "$dev" || true
              # Keep lock for a moment to prevent immediate re-detection
              sleep 3
              rmdir "$lock" 2>/dev/null || true
            ) &
            # FIX #6: Track the background job PID
            active_jobs[$!]="$dev"
            log "$(basename "$dev")" "Spawned job PID $! (active jobs: ${#active_jobs[@]})"
          fi
        fi
      done
      sleep "$POLL_SECS"
    done
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: cd-importer
  namespace: cd-import
spec:
  selector:
    matchLabels: { app: cd-importer }
  template:
    metadata:
      labels: { app: cd-importer }
    spec:
      serviceAccountName: default
      hostPID: true
      hostIPC: true
      # Set fsGroup to match NFS server's gid for proper permissions
      securityContext:
        fsGroup: 65537
        fsGroupChangePolicy: "OnRootMismatch"
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: kubernetes.io/hostname
                operator: NotIn
                values:
                - hp1  # Don't schedule on hp1, has some issue with its cd drive

      containers:
      - name: watcher
        image: ghcr.io/wipash/cdbackuper:latest@sha256:917c9074daba1fed3bcdc0f90a351dd0c7c60309da1eca4281ccdcad295d4e83
        imagePullPolicy: Always
        securityContext:
          privileged: true
          allowPrivilegeEscalation: true
          runAsGroup: 65537
          capabilities:
            add: ["SYS_ADMIN","SYS_RAWIO"]
        env:
          - name: NODE_NAME
            valueFrom:
              fieldRef: { fieldPath: spec.nodeName }
          - name: DATA_ROOT
            value: /data
          - name: RETRIES
            value: "2"
          - name: EXTRACT_FILES
            value: "true"
          - name: DELETE_ISO_ON_SUCCESS
            value: "true"
          - name: TIMEOUT
            value: "7200"
          - name: POLL_SECS
            value: "5"
          - name: DISCORD_WEBHOOK_URL
            valueFrom:
              secretKeyRef:
                name: cd-archiver-config
                key: discord-webhook-url
                optional: true  # Won't fail if secret doesn't exist
        command: ["/usr/local/bin/cd-importer.sh"]
        volumeMounts:
          - name: host-dev
            mountPath: /dev
          - name: host-sys
            mountPath: /sys
            readOnly: true
          - name: udev-run
            mountPath: /run/udev
            readOnly: true
          - name: script
            mountPath: /usr/local/bin/cd-importer.sh
            subPath: cd-importer.sh
          - name: cd-archive
            mountPath: /data
      volumes:
        - name: host-dev
          hostPath: { path: /dev }
        - name: host-sys
          hostPath: { path: /sys }
        - name: udev-run
          hostPath: { path: /run/udev }
        - name: script
          configMap:
            name: cd-watcher
            defaultMode: 0755
        - name: cd-archive
          persistentVolumeClaim:
            claimName: cd-archive-pvc
      tolerations:
        - operator: "Exists"    # schedule everywhere
